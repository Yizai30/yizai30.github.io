---
title: 向量数据库学习
tags: [RAG, Vector Database]
categories: [RAG]
---

# 🎯 第一阶段：基础概念（1-2天）

**核心概念理解**
  1. 什么是向量（Embedding）
    - 向量就是数字数组，代表文本、图像等数据的数学表示
    - 相似的内容，在向量空间中距离更近
    - 示例：[0.1, -0.3, 0.8, ...]
  2. 向量数据库的作用
    - 传统数据库：按精确匹配查找（如 WHERE name = 'Alice'）
    - 向量数据库：按相似度查找（如"找最相似的内容"）
    - 在RAG中的作用：找到与用户问题最相关的文档片段
  3. 相似度计算
    - 余弦相似度：最常用，计算两个向量的角度
    - 欧氏距离：计算两个向点的直线距离
    - 点积：向量的内积

**推荐资源**
  - YouTube搜索："向量数据库入门"、"vector database tutorial"
    - (【上集】向量数据库技术鉴赏)[https://www.youtube.com/watch?v=W_ZUUDJsUtA]
        - 我们可以将文本、图像、视频等数据的特征编码成向量，于是，向量之间的相似度可以用来表示数据之间的关系
        - 为了加快向量相似度计算速度（检索速度），诞生了聚类算法，或同时查找多个聚类以减少遗漏。但这仍然无法解决检索速度和质量的冲突，从而，诞生了位置敏感哈希（LSH, Locality Sensitive Hashing），通过线、平面、超平面分割点，得到正向（1）或负向（0）组成的二进制序列，哈希碰撞函数将发生碰撞的点，或将二进制序列分段后发生一次碰撞的点，放进一个桶中，桶中的点属于一类。
    - (【下集】向量数据库技术鉴赏)[https://www.youtube.com/watch?v=ct20Kv8yn0U]
        - 除了检索速度和质量的问题之外，向量数据所占用的内存在数据量太大的情况下是无法忽视的，例如一个向量是 128 维，每一维用 32 位的浮点型存储，占用 512 个字节，实际场景中千万量级的向量数据并不罕见，那么这些数据大约占用 4.77 GB 的空间，这对内存资源是比较大的消耗。由于每一个向量都有其存在的意义，所以难以在数量上对向量进行删减，于是，考虑减小每一个向量数据的长度。基于这个想法，可以将每一个向量数据分为多个子片段（子向量），例如划分为 8 个 16 维的子向量，在每一个子空间中分别进行 K-means 聚类算法的训练，原始向量的每一个片段，都可以通过相对应的子空间进行量化，每个 16 维子空间大概需要 256 个聚类数量就可以达到较好的效果，因此每个向量的编码范围被“并行量化”为了 0~255，这只需要 1 个字节的空间，而每一个原始向量都可以从这些子片段中还原出来（就是各个子空间中的量化值的查询结果的笛卡尔积）。对于千万量级的向量数据，占用的总空间变成了。这个算法的名字叫做乘积量化（Product Quantization）。简单来说，就是将聚类数量从乘法模式变成了加法模式，解决了维度灾难，一个向量需要 256 位，8 个向量就需要 8 个字节，占用的空间从 4.77 GB 优化为了 8 * 10000000 Byte = 76 MB，优化掉了 98% 的空间。另外，向量内存占用是从开发者的角度出发，但是在用户角度，速度和质量是可以直接被感受到的，所以牺牲一定的内存来优化质量和速度，也视作一种好方法。例如，图数据库，对向量建图，然后查询。相关的算法有导航小世界（NSW, Navigable Small World）、分层的导航小世界 HNSW，HNSW 相对于 NSW 的查询“先粗后细”更加可控。
  - 文档：Pinecone的官方教程（英文，但图示很清晰）：https://docs.pinecone.io/guides/get-started/concepts

以下是 TODO 任务
  ---
# 🛠️ 第二阶段：上手实践（3-5天）

  选择一个向量数据库开始

  我推荐先从 Chroma 开始，因为：
  - 最简单的入门选择
  - Python原生，pip直接安装
  - 适合学习和快速原型开发
  - 不需要账号或云服务

  实践步骤

  1. 安装 Chroma
  pip install chromadb

  2. 第一个示例 - 存储和检索
  创建一个Python脚本：

  import chromadb

  # 创建客户端
  client = chromadb.Client()

  # 创建collection（相当于表）
  collection = client.create_collection("demo")

  # 添加文档
  documents = [
      "Python是一种编程语言",
      "JavaScript用于网页开发",
      "机器学习是人工智能的一个分支",
      "深度学习使用神经网络",
      "向量数据库用于相似度搜索"
  ]

  # 添加到数据库
  collection.add(
      documents=documents,
      ids=["doc1", "doc2", "doc3", "doc4", "doc5"]  # 每个文档的唯一ID
  )

  # 查询相似文档
  results = collection.query(
      query_texts=["什么是人工智能？"],  # 查询文本
      n_results=2  # 返回最相似的2个结果
  )

  print("最相似的文档：")
  for i, doc in enumerate(results['documents'][0], 1):
      print(f"{i}. {doc}")

  3. 使用真实嵌入模型

  import chromadb
  from chromadb.utils import embedding_functions

  # 使用OpenAI的嵌入模型（需要API key）
  openai_ef = embedding_functions.OpenAIEmbeddingFunction(
      api_key="your-api-key-here",
      model_name="text-embedding-3-small"
  )

  # 或者使用免费的模型（不需要API key）
  sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(
      model_name="all-MiniLM-L6-v2"  # 这是一个免费模型
  )

  # 创建collection时指定嵌入模型
  client = chromadb.Client()
  collection = client.create_collection(
      name="rag-demo",
      embedding_function=sentence_transformer_ef
  )

  学习任务
  - 成功运行第一个示例代码
  - 理解 add 和 query 方法的参数
  - 尝试不同的查询文本，观察结果变化
  - 修改 n_results 参数，体验返回不同数量的结果

  ---
  🏗️ 第三阶段：深入特性（5-7天）

  1. 索引和性能优化

  向量数据库的核心是如何快速搜索百万级向量：

  # Chroma自动处理索引，但理解概念很重要
  # 当数据量大时，索引策略至关重要：
  # - HNSW（层次化小世界图）：最常用，平衡速度和精度
  # - IVF（倒排文件）：内存占用更小
  # - Flat（暴力搜索）：最准确但最慢

  # 创建大collection测试性能
  import time

  # 添加大量文档
  large_documents = [f"文档内容 {i}" for i in range(10000)]
  collection.add(
      documents=large_documents,
      ids=[f"doc_{i}" for i in range(10000)]
  )

  # 测试查询速度
  start_time = time.time()
  results = collection.query(
      query_texts=["测试查询"],
      n_results=5
  )
  print(f"查询耗时：{time.time() - start_time:.4f}秒")

  2. 元数据过滤

  向量数据库不只是搜索向量，还可以用元数据过滤：

  # 添加带元数据的文档
  collection.add(
      documents=["Python教程", "JavaScript教程", "机器学习教程"],
      ids=["tech1", "tech2", "tech3"],
      metadatas=[
          {"category": "编程", "difficulty": "入门"},
          {"category": "编程", "difficulty": "中级"},
          {"category": "AI", "difficulty": "高级"}
      ]
  )

  # 查询时过滤元数据
  results = collection.query(
      query_texts=["编程语言"],
      n_results=10,
      where={"category": "编程"}  # 只返回编程类别的
  )

  print("编程类别的相关文档：")
  print(results['documents'][0])

  3. 增量更新和删除

  # 更新文档
  collection.update(
      ids=["tech1"],
      documents=["Python编程语言（已更新）"],
      metadatas=[{"category": "编程", "difficulty": "入门", "updated": True}]
  )

  # 删除文档
  collection.delete(ids=["tech3"])

  # 检查删除后的结果
  results = collection.query(
      query_texts=["教程"],
      n_results=10
  )

  学习任务
  - 测试1000、10000条数据的查询性能
  - 使用元数据过滤功能
  - 练习更新和删除操作
  - 对比不同嵌入模型的性能

  ---
  🌐 第四阶段：生产环境工具（7-10天）

  尝试其他向量数据库

  1. Pinecone（云服务）
    - 优点：管理简单，自动扩展，性能优秀
    - 注册：https://pinecone.io
    - Python SDK：
  import pinecone

  pinecone.init(api_key="your-api-key", environment="us-east-aws")
  index = pinecone.Index("my-index")

  # 查询
  results = index.query(
      vector=query_vector,
      top_k=5,
      include_metadata=True
  )
    - 学习重点：理解服务概念、计费、监控
  2. Milvus（开源，可自部署）
    - 优点：免费、功能强大、适合私有化部署
    - 安装：Docker方式（docker run milvusdb/milvus）
    - 学习重点：部署架构、配置优化
  3. Qdrant（轻量级开源）
    - 优点：简单、快速、易于部署
    - 适合：中小规模项目

  学习任务
  - 注册Pinecone账号并完成官方教程
  - 用Docker运行本地Milvus或Qdrant
  - 比较不同数据库的查询速度和易用性

  ---
  🚀 第五阶段：RAG集成（5-7天）

  在RAG系统中使用向量数据库

  这是你的核心目标！构建一个简单的RAG应用：

  import chromadb
  from chromadb.utils import embedding_functions
  from openai import OpenAI

  # 初始化
  client = chromadb.Client()
  embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction()
  collection = client.get_or_create_collection(
      "rag-knowledge-base",
      embedding_function=embedding_function
  )

  # 1. 加载知识库文档（这是RAG的核心）
  documents = [
      "RAG是一种结合检索和生成的AI技术",
      "向量数据库用于存储文档的向量表示",
      "LLM（大语言模型）负责生成最终答案",
      "RAG系统可以减少模型幻觉",
      "知识库的更新比模型训练更快更便宜"
  ]

  # 2. 添加到向量数据库
  collection.add(
      documents=documents,
      ids=[f"doc_{i}" for i in range(len(documents))],
      metadatas=[{"source": "knowledge-base"} for _ in documents]
  )

  # 3. RAG查询函数
  def rag_query(question, n_retrieved=2):
      # Step 1: 检索相关文档
      results = collection.query(
          query_texts=[question],
          n_results=n_retrieved
      )
      retrieved_docs = results['documents'][0]

      print("📚 检索到的相关文档：")
      for i, doc in enumerate(retrieved_docs, 1):
          print(f"  {i}. {doc}")

      # Step 2: 构建Prompt（这里需要OpenAI API，模拟一下）
      prompt = f"""
      基于以下文档回答问题：

      {chr(10).join(f'- {doc}' for doc in retrieved_docs)}

      问题：{question}
      """

      print("\n🤖 生成答案中...")
      print("(这里会调用LLM生成答案)")
      print(f"Prompt构建完成，内容：\n{prompt}")

      return retrieved_docs

  # 4. 测试
  print("=== RAG系统演示 ===\n")
  rag_query("什么是RAG技术？")
  print("\n" + "="*50 + "\n")
  rag_query("向量数据库在RAG中起什么作用？")

  学习任务
  - 构建完整的RAG知识库
  - 理解检索-生成的流程
  - 测试不同数量的检索文档对答案质量的影响
  - 添加更多文档并测试系统扩展性

  ---
  📊 学习进度检查表

  基础阶段
  - 理解向量和相似度概念
  - 知道向量数据库在RAG中的作用

  实践阶段
  - 安装并运行Chroma
  - 完成第一个增删改查示例
  - 使用不同的嵌入模型

  深入阶段
  - 理解索引和性能优化
  - 掌握元数据过滤
  - 测试大规模数据性能

  生产阶段
  - 使用Pinecone云服务
  - 部署本地向量数据库（Milvus/Qdrant）
  - 对比不同工具的优劣

  应用阶段
  - 构建完整的RAG系统
  - 优化检索质量和速度
  - 处理实际业务场景

  ---
  💡 学习建议

  1. 从简单开始：先学Chroma，不要一开始就搞复杂的部署
  2. 多动手：每学一个概念就写代码验证
  3. 记录笔记：记录遇到的问题和解决方案
  4. 关注性能：当数据量增长时，优化策略会变得很重要
  5. 结合项目：在学习的同时，考虑如何应用到你的实际项目中

  ⏱️ 时间估算

  - 快速入门（能跑通基本示例）：2-3天
  - 深入理解（掌握核心概念）：1-2周
  - 实战应用（构建RAG系统）：2-3周
  - 生产优化（性能、监控、扩展）：持续学习

  ---
  🔗 推荐资源

  文档
  - Chroma官方文档：https://docs.trychroma.com
  - Pinecone教程：https://www.pinecone.io/learn
  - 向量数据库入门：https://www.pinecone.io/learn/vector-database/

  视频
  - B站搜索："向量数据库教程"、"Chroma教程"
  - YouTube：Pinecone的教程视频

  实践项目
  - 构建一个基于文档的问答系统
  - 创建一个产品推荐系统（基于相似度）
  - 开发一个代码搜索工具

